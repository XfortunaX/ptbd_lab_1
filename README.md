# Лабораторная работа №1 по курсу "Технология обработки больших данных"

### Задание

1. Сгенерировать файл состоящий из слов ([a-zA-Z]{3,6}) размером 8 Гб
2. Разбить файл на чанки размером 1 Мб
3. Подсчитать количество одинаковых слов в каждом чанки (Map)
4. Подсчитать количество одинаковых слов во всем чанках (Reduce)

### Требования

1. Node.js 10 или выше
2. Docker

### Выполнение

1. Сгенерировать файл состоящий из слов ([a-zA-Z]{3,6}) размером 8 Гб

```bash
node --expose-gc --max-old-space-size=8192 generateSrc.js
```

Результат - ```dist/words_example_1/words.txt```

2. Разбить файл на чанки размером 1 Мб

```bash
node split.js
```

Результат - ```dist/words_example_1/chunks```

3. Подсчитать количество одинаковых слов в каждом чанки (Map)

```bash
node --max-old-space-size=8192 chunksMap.js
```

Результат - ```dist/words_example_1/chunks_map```

4. Подсчитать количество одинаковых слов во всем чанках (Reduce)

Так как node.js не может хранить в рантайме структуры данных больше ~ 1.5 Гб, а в данном случае необходимо хранить ~ 8 Гб, к тому же может быть ограничения по количеству оперативной памяти на машине и в целом это является плохой практикой, а использование файлов для этого является плохой практикой и плохо масштабируется, то для хранения результата используется хранилище Redis.

```bash
npm install redis

docker run -it --rm -p 6379:6379 -v "$(pwd)"/redisData:/data redis   # команда запустит редис и примонтирует папку в текущей директирории где будет дамп с результатом который можно будет использовать дальше при необходимости

node --max-old-space-size=8192 chunksReduce.js
```

> Использование хранилище замедляет работу программы и Reduce происходит значительно медленнее, но архитектурно правильнее

Результат - ```redisData/dump.rdb```

Для проверки можно использовать следующее

```bash
docker exec -ti <id контейнера> redis-cli

GET <любое слово из words.txt>
```


